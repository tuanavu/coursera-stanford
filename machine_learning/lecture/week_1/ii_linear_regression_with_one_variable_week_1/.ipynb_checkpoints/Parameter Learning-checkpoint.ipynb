{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Table of Contents\n",
    "* [Gradient Descent](#Gradient-Descent)\n",
    "\t* [1) Pictures](#1%29-Pictures)\n",
    "\t* [2) Gradient descent algorithm](#2%29-Gradient-descent-algorithm)\n",
    "* [Gradient Descent Intuition](#Gradient-Descent-Intuition)\n",
    "\t* [1) alpha is positive](#1%29-alpha-is-positive)\n",
    "\t* [2) alpha is negative](#2%29-alpha-is-negative)\n",
    "\t* [3) Understanding alpha](#3%29-Understanding-alpha)\n",
    "* [Gradient Descent for Linear Regression](#Gradient-Descent-for-Linear-Regression)\n",
    "\t* [1) Break down the math](#1%29-Break-down-the-math)\n",
    "\t\t* [a) J = 0:](#a%29-J-=-0:)\n",
    "\t\t* [b) J = 1:](#b%29-J-=-1:)\n",
    "\t* [2) Gradient Descent Algorithm](#2%29-Gradient-Descent-Algorithm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Gradient Descent is a general algorithm which is used to minimize the cost function J."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/lec1_pic17.png\">\n",
    "\n",
    "*Screenshot taken from [Coursera](https://www.coursera.org/learn/machine-learning/lecture/8SpIM/gradient-descent) 1:40*\n",
    "\n",
    "<!--TEASER_END-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Pictures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/lec1_pic18.png\">\n",
    "\n",
    "*Screenshot taken from [Coursera](https://www.coursera.org/learn/machine-learning/lecture/8SpIM/gradient-descent) 3:40*\n",
    "\n",
    "<!--TEASER_END-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Imagine this is like the landscape of some grassy park, with two hills like so, and I want us to imagine that you are physically standing at that point on the hill, on this little red hill in your park. \n",
    "- In gradient descent, what we're going to do is we're going to spin 360 degrees around, just look all around us, and ask,if I were to take a little baby step in some direction, and I want to go downhill as quickly as possible, what direction do I take that little baby step in? \n",
    "- If I wanna go down, so I wanna physically walk down this hill as rapidly as possible. Turns out, that if you're standing at that point on the hill, you look all around and you find that the best direction is to take a little step downhill is roughly that direction. Okay, and now you're at this new point on your hill. You're gonna, again, look all around and say what direction should I step in order to take a little baby step downhill? And if you do that and take another step, you take a step in that direction. And then you keep going. From this new point you look around, decide what direction would take you downhill most quickly. Take another step, another step, and so on until you converge to this local minimum down here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Gradient descent algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/lec1_pic19.png\">\n",
    "\n",
    "*Screenshot taken from [Coursera](https://www.coursera.org/learn/machine-learning/lecture/8SpIM/gradient-descent) 5:19*\n",
    "\n",
    "<!--TEASER_END-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **:=** is the assignment operator. Example: **a := b** or **a := a + 1**\n",
    "- **=** is the truth assertion. Example: **a = b**\n",
    "- $\\Large \\alpha$ is the learning rate, which controls how big a step we take downhill with gradient descent. So if alpha is very large, then that corresponds to a very aggressive gradient descent procedure where we're trying take huge steps downhill and if alpha is very small, then we're taking little, little baby steps downhill.\n",
    "- $\\Large \\frac{d}{d\\theta_{j}}J(\\theta_{0}, \\theta_{1})$ is the derivative term."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **j = 0** and **j = 1** indicates the update of $\\Large \\theta_{0}, \\theta_{1} $. \n",
    "\n",
    "In gradience descent, you want to simultaneously update theta 0 and theta 1. We are gonna update theta 0 := theta 0 minus something, and update theta 1 := theta 1 minus something. And the way to implement is you should compute the right hand side, right? Compute that thing for theta 0 and theta 1 and then simultaneously, at the same time, update theta 0 and theta 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/lec1_pic20.png\">\n",
    "\n",
    "*Screenshot taken from [Coursera](https://www.coursera.org/learn/machine-learning/lecture/8SpIM/gradient-descent) 10:39*\n",
    "\n",
    "<!--TEASER_END-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/lec1_pic21.png\">\n",
    "\n",
    "*Screenshot taken from [Coursera](https://www.coursera.org/learn/machine-learning/lecture/8SpIM/gradient-descent) 10:48*\n",
    "\n",
    "<!--TEASER_END-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent Intuition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) alpha is positive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/lec1_pic22.png\">\n",
    "\n",
    "*Screenshot taken from [Coursera](https://www.coursera.org/learn/machine-learning/lecture/GFFPB/gradient-descent-intuition) 4:08*\n",
    "\n",
    "<!--TEASER_END-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's take a look at the straight line in the cost function. What the derivative at this point does, is basically saying, now let's take the tangent to that point. Drawing a straight line that touches this function, and let's look at the slope of this line. \n",
    "- That's what the derivative is, it's saying what's the slope of the line that is just tangent to the function. \n",
    "- The slope of a line is just this height divided by this horizontal thing. \n",
    "- Now, this line has a positive slope, so it has a positive derivative. And so my update to theta is going to be theta 1, it gets updated as theta 1, minus alpha times some positive number.\n",
    "- Alpha the learning rate, is always a positive number. And, so we're going to take theta one is updated as theta one minus something. So I'm gonna end up moving theta one to the left. I'm gonna decrease theta one, and we can see this is the right thing to do cuz I actually wanna head in this direction. You know, to get me closer to the minimum over there"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) alpha is negative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/lec1_pic23.png\">\n",
    "\n",
    "*Screenshot taken from [Coursera](https://www.coursera.org/learn/machine-learning/lecture/8SpIM/gradient-descent) 5:37*\n",
    "\n",
    "<!--TEASER_END-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In this example, we initialize the parameter over there on the left. This line is slanting down, so this line has negative slope.\n",
    "- We can also say that this function has negative derivative, just means negative slope at that point.\n",
    "- So when we update theta, we have theta of minus alpha times a negative number. I have theta 1 minus a negative number which means I'm actually going to increase theta, because it's minus of a negative number, means I'm adding something to theta.\n",
    "- We will end up increasing theta in order to get closer to the minimum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Understanding alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/lec1_pic24.png\">\n",
    "\n",
    "*Screenshot taken from [Coursera](https://www.coursera.org/learn/machine-learning/lecture/8SpIM/gradient-descent) 8:00*\n",
    "\n",
    "<!--TEASER_END-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If $\\alpha$ is too small, we are taking tiny baby steps to get close to the minimum, gradient descent can be slow.\n",
    "- If $\\alpha$ is too large, gradient descent can overshoot the minimum. We may take a huge step, and end up getting further and further away from the minimum. It may fail to converge, or even diverge.\n",
    "- Convergence and Divergence: http://www.sosmath.com/calculus/improper/convdiv/convdiv.html\n",
    "    - the limit exists (and is a number), in this case we say that the improper integral is convergent;\n",
    "    - the limit does not exist or it is infinite, then we say that the improper integral is divergent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/lec1_pic25.png\">\n",
    "\n",
    "*Screenshot taken from [Coursera](https://www.coursera.org/learn/machine-learning/lecture/8SpIM/gradient-descent) 8:04*\n",
    "\n",
    "<!--TEASER_END-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose your initial value of theta 1 is already at the local minimum. It turns out the local optimum, your derivative will be equal to zero. So for that slope, that tangent point, so the slope of this line will be equal to zero and thus this derivative term is equal to zero. And so your gradient descent update, you have theta one cuz I updated this theta one minus alpha times zero. And so what this means is that if you're already at the local optimum it leaves theta 1 unchanged cause its updates as theta 1 equals theta 1. So if your parameters are already at a local minimum one step with gradient descent does absolutely nothing it doesn't your parameter which is what you want because it keeps your solution at the local optimum. This also explains why gradient descent can converse the local minimum even with the learning rate alpha fixed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<img src=\"images/lec1_pic26.png\">\n",
    "\n",
    "*Screenshot taken from [Coursera](https://www.coursera.org/learn/machine-learning/lecture/8SpIM/gradient-descent) 8:52*\n",
    "\n",
    "<!--TEASER_END-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Gradient descent can converge to a local  minimum, even with the learning rate Î± fixed.\n",
    "- Because as we approach the minimum, the derivative, meaning the slope, becomes less and less steep, and it gets closer and closer to zero.\n",
    "- So after one step of descent, my new derivative is a little bit smaller.\n",
    "- As gradient descent runs, you will automatically take smaller and smaller steps. Until eventually you're taking very small steps, and you finally converge to the to the local minimum. This is what we do not need to decrease alpha over time.\n",
    "- By definition when we reach the local minimum is when the derivative is equal to zero,."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/lec1_pic27.png\">\n",
    "\n",
    "*Screenshot taken from [Coursera](https://www.coursera.org/learn/machine-learning/lecture/8SpIM/gradient-descent) 11:15*\n",
    "\n",
    "<!--TEASER_END-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent for Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In this section, we will apply gradient descent on linear regression to minimize the squared error cost function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/lec1_pic28.png\">\n",
    "\n",
    "*Screenshot taken from [Coursera](https://www.coursera.org/learn/machine-learning/lecture/kCvQc/gradient-descent-for-linear-regression) 00:55*\n",
    "\n",
    "<!--TEASER_END-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now in order to apply gradient descent, the key term we need is the derivative term. So you need to figure out what is this partial derivative term and plugging in the definition of the cost function J."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/lec1_pic29.png\">\n",
    "\n",
    "*Screenshot taken from [Coursera](https://www.coursera.org/learn/machine-learning/lecture/kCvQc/gradient-descent-for-linear-regression) 2:35*\n",
    "\n",
    "<!--TEASER_END-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to understand the partial derivative, we need to understand calculus:\n",
    "\n",
    "https://www.khanacademy.org/math/multivariable-calculus/partial_derivatives_topic/partial_derivatives/v/partial-derivatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Break down the math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) J = 0:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/lec1_pic30.png\">\n",
    "\n",
    "*Screenshot taken from [Coursera](https://www.coursera.org/learn/machine-learning/lecture/kCvQc/gradient-descent-for-linear-regression/discussions/oXheJiOJEeWmISIAC9QOog)*\n",
    "\n",
    "<!--TEASER_END-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{eqnarray}\n",
    "\\frac{\\partial}{\\partial\\theta_{j}}J(\\theta_{0}, \\theta_{1}) &=& \\frac{\\partial}{\\partial\\theta_{j}} \\cdot \\frac{1}{2m}\\sum_{i=1}^m(h_{\\theta}(x^{(i)}) - y^{(i)})^{2} \\nonumber \\\\\n",
    "&=& \\frac{1}{2m}\\sum_{i=1}^m \\cdot \\frac{\\partial}{\\partial\\theta_{j}} \\cdot (h_{\\theta}(x^{(i)}) - y^{(i)})^{2} \\nonumber \\\\\n",
    "&=& \\frac{1}{2m}\\sum_{i=1}^m \\cdot 2(h_{\\theta}(x^{(i)}) - y^{(i)}) \\cdot \\frac{\\partial}{\\partial\\theta_{j}}(h_{\\theta}(x^{(i)}) - y^{(i)})  \\nonumber \\\\\n",
    "&=& \\frac{1}{m}\\sum_{i=1}^m (h_{\\theta}(x^{(i)}) - y^{(i)}) \\cdot \\frac{\\partial}{\\partial\\theta_{j}}(\\theta_{0} + \\theta_{1}x^{(i)} - y^{(i)})  \\nonumber \\\\\n",
    "&=& \\frac{1}{m}\\sum_{i=1}^m (h_{\\theta}(x^{(i)}) - y^{(i)}) \\cdot 1  \\nonumber \\\\\n",
    "\\end{eqnarray}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) J = 1:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/lec1_pic31.png\">\n",
    "\n",
    "*Screenshot taken from [Coursera](https://www.coursera.org/learn/machine-learning/lecture/kCvQc/gradient-descent-for-linear-regression/discussions/oXheJiOJEeWmISIAC9QOog)*\n",
    "\n",
    "<!--TEASER_END-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{eqnarray}\n",
    "\\frac{\\partial}{\\partial\\theta_{j}}J(\\theta_{0}, \\theta_{1}) &=& \\frac{\\partial}{\\partial\\theta_{j}} \\cdot \\frac{1}{2m}\\sum_{i=1}^m(h_{\\theta}(x^{(i)}) - y^{(i)})^{2} \\nonumber \\\\\n",
    "&=& \\frac{1}{2m}\\sum_{i=1}^m \\cdot \\frac{\\partial}{\\partial\\theta_{j}} \\cdot (h_{\\theta}(x^{(i)}) - y^{(i)})^{2} \\nonumber \\\\\n",
    "&=& \\frac{1}{2m}\\sum_{i=1}^m \\cdot 2(h_{\\theta}(x^{(i)}) - y^{(i)}) \\cdot \\frac{\\partial}{\\partial\\theta_{j}}(h_{\\theta}(x^{(i)}) - y^{(i)})  \\nonumber \\\\\n",
    "&=& \\frac{1}{m}\\sum_{i=1}^m (h_{\\theta}(x^{(i)}) - y^{(i)}) \\cdot \\frac{\\partial}{\\partial\\theta_{j}}(\\theta_{0} + \\theta_{1}x^{(i)} - y^{(i)})  \\nonumber \\\\\n",
    "&=& \\frac{1}{m}\\sum_{i=1}^m (h_{\\theta}(x^{(i)}) - y^{(i)}) \\cdot x^{(i)}  \\nonumber \\\\\n",
    "\\end{eqnarray}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Gradient Descent Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/lec1_pic32.png\">\n",
    "\n",
    "*Screenshot taken from [Coursera](https://www.coursera.org/learn/machine-learning/lecture/kCvQc/gradient-descent-for-linear-regression) 4:33*\n",
    "\n",
    "<!--TEASER_END-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the issues we saw with gradient descent is that it can be susceptible to local optima. So when I first explained gradient descent I showed you this picture of it going downhill on the surface, and we saw how depending on where you initialize it, you can end up at different local optima"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/lec1_pic33.png\">\n",
    "\n",
    "*Screenshot taken from [Coursera](https://www.coursera.org/learn/machine-learning/lecture/kCvQc/gradient-descent-for-linear-regression) 4:48*\n",
    "\n",
    "<!--TEASER_END-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But, it turns out that the cost function for linear regression is always going to be a bowl shaped function. The technical term for that is called a convex function. \n",
    "\n",
    "Informally a convex function means a bowl shaped function and so this function doesn't have any local optima except for the one global optimum. This means gradient descent on this type of cost function which you get whenever you're using linear regression it will always converge to the global optimum. Because there are no other local optimum, only global optimum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/lec1_pic34.png\">\n",
    "\n",
    "*Screenshot taken from [Coursera](https://www.coursera.org/learn/machine-learning/lecture/kCvQc/gradient-descent-for-linear-regression) 5:16*\n",
    "\n",
    "<!--TEASER_END-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Visualize how Gradient Descent works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/lec1_pic35.png\">\n",
    "\n",
    "*Screenshot taken from [Coursera](https://www.coursera.org/learn/machine-learning/lecture/kCvQc/gradient-descent-for-linear-regression) 7:28*\n",
    "\n",
    "<!--TEASER_END-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The algorithm we just ran over is called \"Batch\" Gradient Descent**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/lec1_pic36.png\">\n",
    "\n",
    "*Screenshot taken from [Coursera](https://www.coursera.org/learn/machine-learning/lecture/kCvQc/gradient-descent-for-linear-regression) 8:38*\n",
    "\n",
    "<!--TEASER_END-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/lec1_pic37.png\">\n",
    "\n",
    "*Screenshot taken from [Coursera](https://www.coursera.org/learn/machine-learning/lecture/kCvQc/gradient-descent-for-linear-regression) 9:04*\n",
    "\n",
    "<!--TEASER_END-->"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
